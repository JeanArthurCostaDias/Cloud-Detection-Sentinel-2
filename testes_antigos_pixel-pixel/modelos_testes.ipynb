{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c32f00-bd61-4112-b85d-d2c8c53bffb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "import gc\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from osgeo import gdal\n",
    "from osgeo_utils import gdal_merge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c48333e-fb0b-4e6a-b26a-e52730f164a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def cwd(path: str) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Context manager para mudar o diretório de trabalho.\n",
    "    Mantém o diretório original após a execução do bloco de código.\n",
    "    \"\"\"\n",
    "    \n",
    "    oldpwd = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(oldpwd)\n",
    "\n",
    "def listdir_fullpath(d: str) -> List[str]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Retorna uma lista de caminhos completos para os arquivos em um diretório.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [os.path.join(d, f) for f in sorted(os.listdir(d))]\n",
    "\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, caminho: str) -> None:\n",
    "        self.caminho: str = caminho  # Directory where .SAFE images are located\n",
    "        self.abs_caminho: str = os.path.abspath(self.caminho)\n",
    "        self.imgs_diretorio: List[str] = os.listdir(self.caminho)  # Names of each .SAFE image in the directory\n",
    "        self.diretorios_tif: List[str] = sorted([diretorio.replace('.SAFE', '.TIF') for diretorio in self.imgs_diretorio if diretorio.endswith('.SAFE')])\n",
    "        self.caminho_completo_lista: List[str] = [item for item in listdir_fullpath(self.caminho) if item.endswith('.SAFE')]\n",
    "\n",
    "    def merge_tif_files(self, nome_TIF: str, output_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Merges TIFF files into a single file using gdal_merge.\n",
    "        \"\"\"\n",
    "        with cwd(nome_TIF):\n",
    "            if os.path.exists(output_name):\n",
    "                os.remove(output_name)\n",
    "            arquivos_tif: List[str] = glob.glob('*B*.tif')\n",
    "            arquivos_tif: List[str] = self._sort_files(arquivos_tif, sufix='.tif')\n",
    "            parameters = ['', '-o', output_name] + arquivos_tif + ['-separate', '-co', 'BIGTIFF=YES', '-co', 'COMPRESS=LZW']\n",
    "            gdal_merge.main(parameters)\n",
    "            list(map(os.remove, arquivos_tif))\n",
    "\n",
    "    def _create_tif_folder(self) -> None:\n",
    "        \"\"\"\n",
    "        Creates folders that will be used for the model results.\n",
    "        \"\"\"\n",
    "        for tif_dir in self.diretorios_tif:\n",
    "            if os.path.exists(tif_dir):\n",
    "                shutil.rmtree(f'./{tif_dir}')\n",
    "            os.makedirs(tif_dir)\n",
    "        self._modify_img_diretorio()\n",
    "\n",
    "    def _modify_img_diretorio(self) -> None:\n",
    "        self.imgs_diretorio: List[str] = [diretorio for diretorio in self.imgs_diretorio if diretorio.endswith('.SAFE')]\n",
    "\n",
    "    def jp2_to_tif(self, tif_dim: List[str] = ['10980', '10980'], output_name: str = 'merge.tif', create_folder: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Converts JP2 files to TIFF using gdal_translate.\n",
    "        \"\"\"\n",
    "        with cwd(self.caminho):\n",
    "            if create_folder:\n",
    "                self._create_tif_folder()\n",
    "            for diretorio in self.imgs_diretorio:\n",
    "                files: List[str] = glob.glob(os.path.join(f'{diretorio}', 'GRANULE', '*', 'IMG_DATA', '*B*.jp2'))\n",
    "                files: List[str] = self._sort_files(files, sufix='.jp2')\n",
    "                nome_TIF: str = diretorio.replace('.SAFE', '.TIF')\n",
    "                commands: List[List[str]] = []\n",
    "\n",
    "                for f in files:\n",
    "                    input_path: str = f\n",
    "                    output_path: str = nome_TIF + '/' + os.path.splitext(os.path.basename(f))[0] + '.tif'\n",
    "                    if os.path.exists(output_path):\n",
    "                        os.remove(output_path)\n",
    "                    cmd: List[str] = ['gdal_translate', input_path, '-ot', 'Float32', '-of', 'Gtiff', '-outsize', tif_dim[0], tif_dim[1], output_path, '-co', 'BIGTIFF=YES']\n",
    "                    commands.append(cmd)\n",
    "\n",
    "                for cmd in commands:\n",
    "                    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "                self.merge_tif_files(nome_TIF, output_name=output_name)\n",
    "\n",
    "    def _sort_files(self, lista: list, sufix: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Sorts the files list with specific sorting for band B08 and B8A.\n",
    "        \"\"\"\n",
    "        lista = sorted(lista)\n",
    "        b08_name: str = [item for item in lista if item.endswith(f\"B08{sufix}\")][0]\n",
    "        b08_index: int = lista.index(b08_name)\n",
    "        b8A_name: str = [item for item in lista if item.endswith(f\"B8A{sufix}\")][0]\n",
    "        b8A_index: int = lista.index(b8A_name)\n",
    "        lista.insert(b08_index + 1, lista.pop(b8A_index))\n",
    "        return lista\n",
    "\n",
    "\n",
    "class Modelos(Preprocessing):\n",
    "    def __init__(self, caminho: str) -> None:\n",
    "        super().__init__(caminho)\n",
    "\n",
    "    def start(self, create_folder: bool) -> None:\n",
    "        \"\"\"\n",
    "        Starts the preprocessing stage of .jp2 files.\n",
    "        \"\"\"\n",
    "        self.jp2_to_tif(create_folder=create_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f821229-2db5-4c9c-a04b-c269815dc989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def salvar_mascara_tiff(mascara: np.ndarray, banda_exemplo_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves a mask as a TIFF file with georeferencing.\n",
    "    \"\"\"\n",
    "    with rasterio.open(banda_exemplo_path) as src:\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        profile = src.profile\n",
    "\n",
    "        profile.update(\n",
    "            dtype=rasterio.float32,\n",
    "            count=1,\n",
    "            compress='lzw'\n",
    "        )\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(mascara.astype(rasterio.float32), 1)\n",
    "\n",
    "\n",
    "class ModelPreprocessing(Modelos):\n",
    "    @staticmethod\n",
    "    def load_and_prepare_data() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Loads and prepares the data for modeling.\n",
    "        \"\"\"\n",
    "        pixels = pd.concat([pd.read_csv(x) for x in os.listdir() if x.endswith('_pixels.csv')]).drop([f'band_{i}' for i in range(14, 17)], axis=1).drop(['Unnamed: 0', 'x', 'y', 'datetime'], axis=1)\n",
    "        return pixels\n",
    "\n",
    "    @staticmethod\n",
    "    def fmask_replace(pixels: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Replaces the labels for the Fmask model.\n",
    "        \"\"\"\n",
    "        chave = {0: 0, 1: 1, 2: 2, 4: 3}\n",
    "        fmask = pixels[pixels['modelo'] == 'Fmask']['GrndTruth'].replace(chave)\n",
    "        return fmask\n",
    "\n",
    "    @staticmethod\n",
    "    def kappa_replace(pixels: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Replaces the labels for the Kappa model.\n",
    "        \"\"\"\n",
    "        chave = {1: 0, 2: 2, 3: 4, 4: 3}\n",
    "        kappa = pixels[pixels['modelo'].isin(['Kappamask', 'KappaMask'])]['GrndTruth'].replace(chave)\n",
    "        return kappa\n",
    "\n",
    "    @staticmethod\n",
    "    def sen2cor_replace(pixels: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Replaces the labels for the Sen2Cor model.\n",
    "        \"\"\"\n",
    "        chave = {2: 2, 3: 2, 4: 0, 5: 0, 6: 1, 8: 3, 9: 3, 10: 4}\n",
    "        sen2cor = pixels[pixels['modelo'].isin(['Sen2Core', 'Sen2Cor'])]['GrndTruth'].replace(chave)\n",
    "        return sen2cor\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_labels(pixels: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Replaces the labels in the pixels DataFrame.\n",
    "        \"\"\"\n",
    "        fmask_rotulos = ModelPreprocessing.fmask_replace(pixels)\n",
    "        kappa_rotulos = ModelPreprocessing.kappa_replace(pixels)\n",
    "        sen2cor_rotulos = ModelPreprocessing.sen2cor_replace(pixels)\n",
    "        pixels['GrndTruth'] = pd.concat([fmask_rotulos, kappa_rotulos, sen2cor_rotulos]).values\n",
    "        return pixels\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_features_and_labels(pixels: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Prepares features and labels for modeling.\n",
    "        \"\"\"\n",
    "        pixels = pixels.reset_index().drop('index', axis=1).drop('modelo', axis=1)\n",
    "        X = pixels.drop(['GrndTruth'], axis=1).dropna()\n",
    "        y = pixels.loc[X.index, 'GrndTruth']\n",
    "        return X, y\n",
    "\n",
    "    @staticmethod\n",
    "    def split_data(X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        \"\"\"\n",
    "        Splits the data into training and testing sets.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def infer_model(self, diretorio: str, model: object, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Infers the model on the data.\n",
    "        \"\"\"\n",
    "        if os.path.exists(diretorio):\n",
    "            with cwd(diretorio):\n",
    "                start = time.time()\n",
    "\n",
    "                pipeline = Pipeline([\n",
    "                    ('scaler', StandardScaler()),  # Data normalization\n",
    "                    ('pca', PCA(n_components=11)),  # Dimensionality reduction with PCA\n",
    "                    ('classifier', model)  # Classifier\n",
    "                ])\n",
    "\n",
    "                dataset = gdal.Open('./merge.tif')\n",
    "                cols = dataset.RasterXSize\n",
    "                rows = dataset.RasterYSize\n",
    "                bands = dataset.RasterCount\n",
    "\n",
    "                transposed_shape = (rows, cols, bands)\n",
    "                bandas = np.memmap('transposed_array.dat', dtype=np.float32, mode='r', shape=transposed_shape)\n",
    "                del dataset\n",
    "                gc.collect()\n",
    "\n",
    "                bandas = (bandas - 1000) / 10000\n",
    "                bandas = bandas.clip(min=0)\n",
    "\n",
    "                start = time.time()\n",
    "                pipeline.fit(X, y)\n",
    "\n",
    "                column_names = [f'band_{i+1}' for i in range(bands)]\n",
    "                df = pd.DataFrame(bandas, columns=column_names)\n",
    "                chunk_size = 10000\n",
    "                output_file = 'predictions.csv'\n",
    "\n",
    "                with open(output_file, 'w') as f:\n",
    "                    f.write('predictions\\n')\n",
    "\n",
    "                def process_chunk(chunk: pd.DataFrame) -> np.ndarray:\n",
    "                    predictions = pipeline.predict(chunk)\n",
    "                    return predictions\n",
    "\n",
    "                num_pixels = df.shape[0]\n",
    "\n",
    "                for start in range(0, num_pixels, chunk_size):\n",
    "                    end = min(start + chunk_size, num_pixels)\n",
    "                    chunk = df.iloc[start:end]\n",
    "                    chunk_predictions = process_chunk(chunk)\n",
    "\n",
    "                    with open(output_file, 'a') as f:\n",
    "                        for prediction in chunk_predictions:\n",
    "                            f.write(f\"{prediction}\\n\")\n",
    "\n",
    "                    del chunk_predictions, chunk\n",
    "                    gc.collect()\n",
    "\n",
    "                end = time.time()\n",
    "                print(\"Tempo total para detecção de nuvens:\", end - start, \"segundos\")\n",
    "                gc.collect()\n",
    "                return pd.read_csv(output_file)\n",
    "\n",
    "\n",
    "def main(obj: ModelPreprocessing, diretorio: str) -> Tuple[List[str], dict]:\n",
    "    \"\"\"\n",
    "    Main function to train models and make predictions.\n",
    "    \"\"\"\n",
    "    pixels = ModelPreprocessing.load_and_prepare_data()\n",
    "    pixels = ModelPreprocessing.replace_labels(pixels)\n",
    "    X, y = ModelPreprocessing.prepare_features_and_labels(pixels)\n",
    "\n",
    "    models = {\n",
    "        'Voting_XGB_AdaBoost': VotingClassifier(estimators=[\n",
    "            ('xgb', XGBClassifier(random_state=42)),\n",
    "            ('adaboost', AdaBoostClassifier(random_state=42))\n",
    "        ], voting='soft'),\n",
    "        'ExtraTrees': ExtraTreesClassifier(random_state=42),\n",
    "        'XGBClassifier': XGBClassifier(random_state=42),\n",
    "        'Voting_LGBM_AdaBoost': VotingClassifier(estimators=[\n",
    "            ('lgbm', LGBMClassifier(random_state=42)),\n",
    "            ('adaboost', AdaBoostClassifier(random_state=42))\n",
    "        ], voting='soft'),\n",
    "        'LGBMClassifier': LGBMClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X, y)\n",
    "        predictions = obj.infer_model(diretorio, model, X)\n",
    "        results[model_name] = predictions\n",
    "\n",
    "    return list(results.keys()), results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ponto_de_montagem = '/media/jean/90D8B801D8B7E41E/Ubuntu/' # Pasta onde as imagens .SAFE estão \n",
    "    for i in sorted(os.listdir(ponto_de_montagem)):\n",
    "        destino = os.path.join(os.path.abspath(ponto_de_montagem), i)\n",
    "        obj = ModelPreprocessing(destino)\n",
    "        obj.start(create_folder=True)\n",
    "        for diretorio in obj.diretorios_tif:\n",
    "            caminho_completo = os.path.join(obj.caminho, diretorio)\n",
    "            nomes_modelos, resultados = main(obj, caminho_completo)\n",
    "\n",
    "            banda_path = os.path.join(destino, diretorio, 'merge.tif')\n",
    "\n",
    "            for nome in nomes_modelos:\n",
    "                output_path = os.path.join(destino, diretorio, f\"{nome}.tif\")\n",
    "                salvar_mascara_tiff(resultados[nome], banda_path, output_path)\n",
    "                gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
