{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175576f0-35d7-4c57-a946-26780886a929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from functools import lru_cache\n",
    "from typing import List, Union, Tuple\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import torch\n",
    "from numba import jit\n",
    "\n",
    "from osgeo import gdal\n",
    "import osgeo_utils.gdal_merge\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, recall_score, f1_score, precision_score, \n",
    "                             confusion_matrix, matthews_corrcoef, cohen_kappa_score, \n",
    "                             hamming_loss, classification_report)\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def cwd(path: str) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Context manager para mudar o diretório de trabalho.\n",
    "    Mantém o diretório original após a execução do bloc\n",
    "    \n",
    "    o de código.\n",
    "    \"\"\"\n",
    "\n",
    "    oldpwd = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(oldpwd)\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize, edgeitems=sys.maxsize, linewidth=sys.maxsize, precision=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d801a-d4ed-4ba7-9008-bcb7f7712e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60"
     ]
    }
   ],
   "source": [
    "def listdir_fullpath(d: str) -> List[str]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Retorna uma lista de caminhos completos para os arquivos em um diretório.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [os.path.join(d, f) for f in sorted(os.listdir(d))]\n",
    "\n",
    "class AmbienteIncorretoError(Exception):\n",
    "    def __init__(self):\n",
    "        self.message = \"Necessário estar no ambiente 'km_predict' para rodar o modelo\"\n",
    "        super().__init__(self.message)\n",
    "\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, caminho: str) -> None:\n",
    "        self.caminho: str = caminho  # Pasta onde as imagens .SAFE estão\n",
    "        self.abs_caminho: str = os.path.abspath(self.caminho)\n",
    "        self.imgs_diretorio: List[str] = os.listdir(self.caminho)  # Nome de cada imagem .SAFE no diretório\n",
    "        self.diretorios_tif: List[str] = sorted([diretorio.replace('.SAFE', '.TIF') for diretorio in self.imgs_diretorio if diretorio.endswith('.SAFE')])\n",
    "        self.caminho_completo_lista: List[str] = [item for item in listdir_fullpath(self.caminho) if item.endswith('.SAFE')]\n",
    "\n",
    "    def merge_tif_files(self, nome_TIF: str, output_name:str) -> None:\n",
    "        \"\"\"\n",
    "        Mescla arquivos TIFF em um único arquivo usando gdal_merge.\n",
    "        \"\"\"\n",
    "        with cwd(nome_TIF):\n",
    "            if os.path.exists(output_name):\n",
    "                os.remove(output_name)\n",
    "            arquivos_tif: List[str] = glob.glob('*B*.tif')\n",
    "            arquivos_tif: List[str] = self._sort_files(arquivos_tif,sufix='.tif')\n",
    "            comando: List[str] = ['gdal_merge.py', '-o', output_name, '-of', 'Gtiff', '-separate', '-ot', 'FLOAT32', '-co', 'BIGTIFF=YES'] + arquivos_tif\n",
    "            parameters = ['', '-o', output_name] + arquivos_tif + ['-separate', '-co', 'COMPRESS=LZW','-co','BIGTIFF=YES','-co', 'COMPRESS=LZW']\n",
    "            osgeo_utils.gdal_merge.main(parameters)\n",
    "            list(map(os.remove, arquivos_tif))\n",
    "\n",
    "    def _create_tif_folder(self) -> None:\n",
    "        \"\"\"\n",
    "        Cria pastas que serão utilizadas para o resultado dos modelos.\n",
    "        \"\"\"\n",
    "        for tif_dir in self.diretorios_tif:\n",
    "            if os.path.exists(tif_dir):\n",
    "                shutil.rmtree(f'./{tif_dir}')\n",
    "            os.makedirs(tif_dir)\n",
    "        self._modify_img_diretorio()\n",
    "\n",
    "    def _modify_img_diretorio(self) -> None:\n",
    "        self.imgs_diretorio: List[str] = [diretorio for diretorio in self.imgs_diretorio if diretorio.endswith('.SAFE')]\n",
    "\n",
    "    def jp2_to_tif(self, tif_dim: List[str] = ['10980','10980'], output_name: str = 'merge.tif', create_folder:bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Converte arquivos JP2 para TIFF usando gdal_translate.\n",
    "        \"\"\"\n",
    "        with cwd(self.caminho):\n",
    "            if create_folder:\n",
    "                self._create_tif_folder()\n",
    "            for diretorio in self.imgs_diretorio:\n",
    "                files: List[str] = glob.glob(os.path.join(f'{diretorio}', 'GRANULE', '*', 'IMG_DATA', '*B*.jp2'))\n",
    "                files: List[str] = self._sort_files(files,sufix='.jp2')\n",
    "                nome_TIF: str = diretorio.replace('.SAFE', '.TIF')\n",
    "                commands: List[List[str]] = []\n",
    "                \n",
    "                for f in files:\n",
    "                    input_path: str = f\n",
    "                    output_path: str = nome_TIF + '/' + os.path.splitext(os.path.basename(f))[0] + '.tif'\n",
    "                    if os.path.exists(output_path):\n",
    "                        os.remove(output_path)\n",
    "                    cmd: List[str] = ['gdal_translate', input_path, '-ot', 'Float32', '-of', 'Gtiff', '-outsize', tif_dim[0], tif_dim[1], output_path, '-co', 'BIGTIFF=YES']\n",
    "                    commands.append(cmd)\n",
    "                    \n",
    "                for cmd in commands:\n",
    "                    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "                    \n",
    "                self.merge_tif_files(nome_TIF,output_name=output_name)\n",
    "            \n",
    "                    \n",
    "                    \n",
    "    def _sort_files(self, lista: list, sufix: str):\n",
    "        lista = sorted(lista)\n",
    "\n",
    "        b08_name: int = [item for item in lista if item.endswith(f\"B08{sufix}\")][0]\n",
    "        b08_index: int = lista.index(b08_name)\n",
    "\n",
    "        b8A_name: int = [item for item in lista if item.endswith(f\"B8A{sufix}\")][0]\n",
    "        b8A_index: int = lista.index(b8A_name)\n",
    "\n",
    "        lista.insert(b08_index + 1, lista.pop(b8A_index))\n",
    "        \n",
    "        return lista\n",
    "\n",
    "    def _criar_symlinks_kappaMask(self, kappa_mask_folder: str) -> None:\n",
    "        \"\"\"\n",
    "        Cria symlinks para pasta \"data\" do kappamask.\n",
    "        \"\"\"\n",
    "        with cwd(kappa_mask_folder):\n",
    "            if not os.path.exists('./data'):\n",
    "                os.makedirs('data')\n",
    "                \n",
    "        pasta_origem: str = os.path.abspath(kappa_mask_folder)\n",
    "        for diretorio in self.caminho_completo_lista:\n",
    "            caminho_pasta: str = self.caminho + '/' + diretorio\n",
    "            pasta_destino: str = os.path.abspath(caminho_pasta)\n",
    "            symlink_path: str = os.path.join(pasta_origem, \"data\", os.path.basename(pasta_destino))\n",
    "            try:\n",
    "                os.symlink(pasta_destino, symlink_path)\n",
    "                print(f\"Symlink criado com sucesso: {symlink_path} -> {pasta_destino}\")\n",
    "            except FileExistsError:\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao criar symlink: {e}\")\n",
    "\n",
    "    def _config_json_kappa(self, kappa_mask_folder, product_name, architecture, json_config_name) -> None:\n",
    "        diretorio_atual = self.abs_caminho\n",
    "        print(diretorio_atual)\n",
    "        json_config: dict = {\n",
    "            \"cm_vsm_executable\": \"cm_vsm\",\n",
    "            \"folder_name\": f\"{diretorio_atual}\",\n",
    "            \"product_name\": f\"{product_name.replace('.SAFE','')}\",\n",
    "            \"level_product\": \"L1C\",\n",
    "            \"overlapping\": 0.0625,\n",
    "            \"tile_size\": 512,\n",
    "            \"resampling_method\": \"sinc\",\n",
    "            \"architecture\": f\"{architecture}\",\n",
    "            \"batch_size\": 1,\n",
    "            \"aoi_geometry\": \"\"\n",
    "        }\n",
    "        caminho_json_config: str = f'./config/{json_config_name}'\n",
    "        with cwd(kappa_mask_folder):\n",
    "            with open(caminho_json_config, 'w') as arquivo:\n",
    "                json.dump(json_config, arquivo, indent=2)\n",
    "\n",
    "class Modelos(Preprocessing):\n",
    "    def __init__(self, caminho: str) -> None:\n",
    "        self.caminho = caminho\n",
    "        super().__init__(caminho)\n",
    "\n",
    "    def start(self,create_folder) -> None:\n",
    "        \"\"\"Começa a etapa de pré-processamento dos arquivos .jp2\"\"\"\n",
    "        self.jp2_to_tif(create_folder=create_folder)\n",
    "        df = Modelos.get_gt_predict(self.caminho.split('/')[-1].upper())\n",
    "        with cwd(self.caminho):\n",
    "            list(map(shutil.rmtree, self.diretorios_tif))\n",
    "        return df\n",
    "        \n",
    "    @staticmethod\n",
    "    def read_tif_values(tif_path, x, y):\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            # Converte as coordenadas x, y em índices de linha e coluna no raster\n",
    "            row, col = src.index(x, y)\n",
    "            values = []\n",
    "            for i in range(1, src.count + 1):  # Para cada banda\n",
    "                window = Window(col, row, 1, 1)\n",
    "                band_values = src.read(i, window=window)\n",
    "                values.append(band_values[0][0])\n",
    "            return values\n",
    "\n",
    "    @staticmethod\n",
    "    def tifs(df_rotulos, index, name,regiao):\n",
    "        ponto_de_montagem = f'/media/jean/90D8B801D8B7E41E/Ubuntu/{regiao.title()}'\n",
    "        destino = os.path.abspath(ponto_de_montagem)\n",
    "        with cwd(destino):\n",
    "            with cwd(name):\n",
    "                geotiff_path = 'merge.tif'\n",
    "                # Lista para armazenar os valores das bandas\n",
    "                band_values_list = []\n",
    "\n",
    "                # Itera sobre cada linha do dataframe\n",
    "                for _, row in df_rotulos.iterrows():\n",
    "                    x, y = row['x'], row['y']\n",
    "                    values = Modelos.read_tif_values(geotiff_path, x, y)\n",
    "                    band_values_list.append(values)\n",
    "\n",
    "                # Adiciona os valores das bandas ao dataframe original\n",
    "                band_values_array = np.array(band_values_list)\n",
    "                for i in range(band_values_array.shape[1]):\n",
    "                    df_rotulos[f'band_{i + 1}'] = band_values_array[:, i]\n",
    "\n",
    "                return df_rotulos\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_gt_predict(regiao):\n",
    "        def get_value_from_data_df(row):\n",
    "            return data_df[row['x']][float(row['y'])]\n",
    "        resultado = {}\n",
    "        with cwd('./Pontos_Validados/'):\n",
    "            with cwd(f'./{regiao.upper()}'):\n",
    "                dates = [x for x in os.listdir() if not x in (\".ipynb_checkpoints\")]\n",
    "                i=0\n",
    "                for data in dates:\n",
    "                    date = f'{data}/'\n",
    "                    print(date)\n",
    "                    with cwd(date):\n",
    "                        models = [x for x in sorted(os.listdir()) if ( x != \".ipynb_checkpoints\") and (not(x.endswith('.xml'))) and (not(x.endswith('.jp2')))]\n",
    "                        for model in models:\n",
    "                            with cwd(os.path.join(model)):\n",
    "                                xml = [x for x in os.listdir(f'../') if x.endswith(\"xml\")][0].split('_')[4:11]\n",
    "                                name = '_'.join(xml).replace('.SAFE','.TIF')\n",
    "                                files = sorted(os.listdir())  \n",
    "                                shp = [shp for shp in files if shp.endswith('.shp')][0]\n",
    "                                shapefile = gpd.read_file(shp)\n",
    "                                new_df = shapefile['geometry'].get_coordinates()\n",
    "                                df = pd.concat([new_df,shapefile['GrndTruth']],axis=1)\n",
    "                                df['datetime'] = pd.to_datetime(data.replace('(1)','').replace('_','/'),dayfirst=True)\n",
    "                                df = Modelos.tifs(df,i,name,regiao)\n",
    "                                resultado[f'{regiao}_{model}_{data}'] = df\n",
    "        return resultado\n",
    "\n",
    "pasta_principal = '/media/jean/90D8B801D8B7E41E/Ubuntu/'\n",
    "for i in os.listdir(pasta_principal)[1:]:\n",
    "    pasta_regiao = os.path.abspath(os.path.join(pasta_principal,i))\n",
    "    obj: Modelos = Modelos(pasta_regiao)\n",
    "    teste_df_regiao = obj.start(create_folder=True)  # Executar uma ÚNICA vez na pasta no qual as imagens estão.\n",
    "    pd.concat(teste_df_regiao.values(),axis=0).to_csv(f'{i.title()}_pixels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
